{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skE27y_95d_D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Autor: Lucas Moreira\n",
        "Projeto: ETL de dados Fenabrave (Novos e Seminovos/Usados)\n",
        "Descrição: Notebook de captura dos dados no PDF e tratamento\n",
        "Data: 2025-06\n",
        "\"\"\"\n",
        "\n",
        "import urllib\n",
        "import fitz  #PyMuPDF\n",
        "import sqlite3\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import re\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from oauth2client.service_account import ServiceAccountCredentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJkk9ie8EJe"
      },
      "source": [
        "### Reading PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik0bpePw4vb2"
      },
      "outputs": [],
      "source": [
        "path_used = 'input/usados'\n",
        "lista_arquivos = os.listdir(path_used)\n",
        "\n",
        "path_new = 'input/novos'\n",
        "lista_arquivos_new = os.listdir(path_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecj6H9W1T-4q"
      },
      "source": [
        "### Seminovos e Usados\n",
        "\n",
        "1. Cria função para captura da tabela principal (consolidado por segmento)\n",
        "2. Extrai dados de cada arquivo\n",
        "3. Extrai o ranking dos 50 Autos e 50 Comerciais Leves mais vendidos no mês"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTnzPRvLAiUV"
      },
      "outputs": [],
      "source": [
        "def extract_total_used(texto, nome_arquivo):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados consolidados do mês para o total de seminovos e usados transacionados\n",
        "    \"\"\"\n",
        "    total_used = []\n",
        "    pattern = re.compile(\n",
        "        r\"(A\\)\\s*Autos|B\\)\\s*Com\\.?\\s*Leves|A\\s*\\+\\s*B|C\\)\\s*Caminh[oõ]es|D\\)\\s*Ônibus|C\\s*\\+\\s*D|Subtotal|E\\)\\s*Motos|F\\)\\s*Impl\\.?\\s*Rod\\.?|Outros|Total)\\s+([\\d.]+)\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for match in pattern.finditer(texto):\n",
        "        segmento = match.group(1).strip()\n",
        "        total = int(match.group(2).replace('.', ''))\n",
        "        total_used.append({\n",
        "            \"segmento\": segmento,\n",
        "            \"total\": total,\n",
        "            \"arquivo\": nome_arquivo\n",
        "        })\n",
        "\n",
        "        # Interrompe após os primeiros registros de interesse\n",
        "        if segmento.lower() == \"total\" or len(total_used) == 11:\n",
        "            break\n",
        "\n",
        "    return total_used\n",
        "\n",
        "\n",
        "# Coleta os dados de todos os PDFs\n",
        "total_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos:\n",
        "    if nome_arquivo.endswith(\".pdf\"):\n",
        "        caminho_pdf = os.path.join(path_used, nome_arquivo)\n",
        "        try:\n",
        "            doc = fitz.open(caminho_pdf)\n",
        "            texto_total = \"\"\n",
        "            for pagina in doc:\n",
        "                texto_total += pagina.get_text(\"text\")\n",
        "            doc.close()\n",
        "\n",
        "            resultados = extract_total_used(texto_total, nome_arquivo)\n",
        "            total_data.extend(resultados)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {nome_arquivo}: {e}\")\n",
        "\n",
        "df_total_used = pd.DataFrame(total_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDZaYcis-Qce"
      },
      "outputs": [],
      "source": [
        "# Dicionário para renomear os segmentos\n",
        "rename_dict = {\n",
        "    \"A) Autos\": \"Autos\",\n",
        "    \"B) Com. Leves\": \"Comerciais Leves\",\n",
        "    \"C) Caminhões\": \"Caminhões\",\n",
        "    \"D) Ônibus\": \"Ônibus\",\n",
        "    \"E) Motos\": \"Motos\",\n",
        "    \"F) Impl. Rod.\": \"Implementos Rodoviários\",\n",
        "    \"Outros\": \"Outros\"\n",
        "}\n",
        "df_total_used[\"segmento\"] = df_total_used[\"segmento\"].str.strip().replace(rename_dict)\n",
        "\n",
        "# Remove linhas com segmentos agregados\n",
        "excluir = {\"A + B\", \"C + D\", \"Subtotal\", \"Total\"}\n",
        "df = df_total_used[~df_total_used[\"segmento\"].isin(excluir)]\n",
        "\n",
        "# Extrai o padrão 'YYYY_MM'\n",
        "df_total_used[\"ano_mes\"] = df_total_used[\"arquivo\"].apply(lambda x: re.search(r\"\\d{4}_\\d{2}\", x).group(0) if re.search(r\"\\d{4}_\\d{2}\", x) else \"N/A\")\n",
        "df_total_used.drop(['arquivo'], axis=1, inplace=True)\n",
        "df_total_used.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Pivota por ano_mes\n",
        "pivot_df_total_used = df_total_used.pivot(index='ano_mes', columns='segmento', values='total').reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LyVNVl6CC73"
      },
      "outputs": [],
      "source": [
        "def extract_ranking_used_autos(text):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados do ranking dos 50 Autos mais comercializados no mês\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    pattern = r'(\\d+º)\\s+([\\w\\s-]+)\\s+([\\d.]+)'\n",
        "    data = re.findall(pattern, \"\\n\".join(lines))\n",
        "    return data[:50]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos:\n",
        "    if nome_arquivo.endswith('.pdf'):\n",
        "        caminho_pdf = os.path.join(path_used, nome_arquivo)\n",
        "\n",
        "        pdf_document = fitz.open(caminho_pdf)\n",
        "\n",
        "        todo_texto = \"\"\n",
        "        for num_pagina in range(pdf_document.page_count):\n",
        "            pagina = pdf_document[num_pagina]\n",
        "            todo_texto += pagina.get_text(\"text\")\n",
        "\n",
        "        pdf_document.close()\n",
        "\n",
        "        data = extract_ranking_used_autos(todo_texto)\n",
        "\n",
        "        if data:\n",
        "            match = re.search(r'(\\d{4}_\\d{2})', nome_arquivo)\n",
        "            if match:\n",
        "                ano_mes = match.group(1)\n",
        "            else:\n",
        "                print(f\"Aviso: padrão 'YYYY_MM' não encontrado em {nome_arquivo}\")\n",
        "                continue  # pula esse arquivo\n",
        "\n",
        "            for i, dados_entrada in enumerate(data, start=1):\n",
        "                lista_entrada = list(dados_entrada)\n",
        "                lista_entrada[0] = f\"{i}º\"\n",
        "                lista_entrada.append(ano_mes)\n",
        "                all_data.append(lista_entrada)\n",
        "\n",
        "used_autos = pd.DataFrame(all_data, columns=[\"ranking\", \"model\", \"total\", \"ano_mes\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PGI4OXnK2AM"
      },
      "outputs": [],
      "source": [
        "def extract_ranking_used_light(text):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados do ranking dos 50 Comerciais Leves mais comercializados no mês\n",
        "    \"\"\"\n",
        "    blocos = re.split(r'(?=\\d{1,2}º)', text)\n",
        "    resultados = []\n",
        "    for bloco in blocos:\n",
        "        match = re.search(r'(\\d{1,2}º)[\\s\\n]+([A-Z0-9 \\-]+)[\\s\\n]+([\\d.]+)', bloco)\n",
        "        if match:\n",
        "            ranking = match.group(1)\n",
        "            modelo = match.group(2).strip()\n",
        "            total = match.group(3).replace('.', '')\n",
        "            resultados.append((ranking, modelo, int(total)))\n",
        "    return resultados[50:]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos:\n",
        "    if nome_arquivo.endswith('.pdf'):\n",
        "        caminho_pdf = os.path.join(path_used, nome_arquivo)\n",
        "\n",
        "        pdf_document = fitz.open(caminho_pdf)\n",
        "\n",
        "        todo_texto = \"\"\n",
        "        for num_pagina in range(pdf_document.page_count):\n",
        "            pagina = pdf_document[num_pagina]\n",
        "            todo_texto += pagina.get_text(\"text\")\n",
        "\n",
        "        pdf_document.close()\n",
        "\n",
        "        data = extract_ranking_used_light(todo_texto)\n",
        "\n",
        "        if data:\n",
        "            match = re.search(r'(\\d{4}_\\d{2})', nome_arquivo)\n",
        "            if match:\n",
        "                ano_mes = match.group(1)\n",
        "            else:\n",
        "                print(f\"Aviso: padrão 'YYYY_MM' não encontrado em {nome_arquivo}\")\n",
        "                continue\n",
        "\n",
        "            for i, dados_entrada in enumerate(data, start=1):\n",
        "                lista_entrada = list(dados_entrada)\n",
        "                lista_entrada[0] = f\"{i}º\"\n",
        "                lista_entrada.append(ano_mes)\n",
        "                all_data.append(lista_entrada)\n",
        "\n",
        "used_leves = pd.DataFrame(all_data, columns=[\"ranking\", \"model\", \"total\", \"ano_mes\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9pZw_xT00Z"
      },
      "source": [
        "### Emplacamentos\n",
        "\n",
        "1. Utiliza da mesma função para capturar a tabela principal (consolidado por segmento)\n",
        "2. Extrai a tabela de de cada arquivo com o resultado mensal. Faz ajustes finos retirando subtotais e ajustando nomes. Pivota a tabela.\n",
        "3. Extrai o ranking dos 50 Autos e 50 Comerciais Leves mais vendidos no mês"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyuUGYCWv8ly"
      },
      "outputs": [],
      "source": [
        "def extract_total_used(texto, nome_arquivo):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados consolidados do mês para o total de emplacamentos\n",
        "    \"\"\"\n",
        "    total_new = []\n",
        "    pattern = re.compile(\n",
        "        r\"(A\\)\\s*Autos|B\\)\\s*Com\\.?\\s*Leves|A\\s*\\+\\s*B|C\\)\\s*Caminh[oõ]es|D\\)\\s*Ônibus|C\\s*\\+\\s*D|Subtotal|E\\)\\s*Motos|F\\)\\s*Impl\\.?\\s*Rod\\.?|Outros|Total)\\s+([\\d.]+)\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    for match in pattern.finditer(texto):\n",
        "        segmento = match.group(1).strip()\n",
        "        total = int(match.group(2).replace('.', ''))\n",
        "        total_new.append({\n",
        "            \"segmento\": segmento,\n",
        "            \"total\": total,\n",
        "            \"arquivo\": nome_arquivo\n",
        "        })\n",
        "\n",
        "        # Interrompe após os registros de interesse\n",
        "        if segmento.lower() == \"total\" or len(total_new) == 11:\n",
        "            break\n",
        "\n",
        "    return total_new\n",
        "\n",
        "\n",
        "# Coleta os dados de todos os PDFs\n",
        "total_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos_new:\n",
        "    if nome_arquivo.endswith(\".pdf\"):\n",
        "        caminho_pdf = os.path.join(path_new, nome_arquivo)\n",
        "        try:\n",
        "            doc = fitz.open(caminho_pdf)\n",
        "            texto_total = \"\"\n",
        "            for pagina in doc:\n",
        "                texto_total += pagina.get_text(\"text\")\n",
        "            doc.close()\n",
        "\n",
        "            resultados = extract_total_used(texto_total, nome_arquivo)\n",
        "            total_data.extend(resultados)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {nome_arquivo}: {e}\")\n",
        "\n",
        "# Cria o DataFrame\n",
        "df_total_new = pd.DataFrame(total_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt1pF2ewTF6Z"
      },
      "outputs": [],
      "source": [
        "# Dicionário para renomear os segmentos\n",
        "rename_dict = {\n",
        "    \"A) Autos\": \"Autos\",\n",
        "    \"B) Com. Leves\": \"Comerciais Leves\",\n",
        "    \"C) Caminhões\": \"Caminhões\",\n",
        "    \"D) Ônibus\": \"Ônibus\",\n",
        "    \"E) Motos\": \"Motos\",\n",
        "    \"F) Impl. Rod.\": \"Implementos Rodoviários\",\n",
        "    \"Outros\": \"Outros\",\n",
        "    \"OUTROS\": \"Outros\"\n",
        "}\n",
        "df_total_new[\"segmento\"] = df_total_new[\"segmento\"].str.strip().replace(rename_dict)\n",
        "\n",
        "# Remove linhas com segmentos agregados\n",
        "excluir = {\"A + B\", \"C + D\", \"Subtotal\", \"Total\"}\n",
        "df_novos = df_total_new[~df_total_new[\"segmento\"].isin(excluir)]\n",
        "\n",
        "# Extrai o padrão 'YYYY_MM'\n",
        "df_total_new[\"ano_mes\"] = df_total_new[\"arquivo\"].apply(lambda x: re.search(r\"\\d{4}_\\d{2}\", x).group(0) if re.search(r\"\\d{4}_\\d{2}\", x) else \"N/A\")\n",
        "df_total_new.drop(['arquivo'], axis=1, inplace=True)\n",
        "df_total_new.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Elimina duplicados\n",
        "df_total_new = df_total_new.groupby(['ano_mes', 'segmento'])['total'].max().reset_index()\n",
        "\n",
        "# Pivota por ano_mes\n",
        "pivot_df_total_new = df_total_new.pivot(index='ano_mes', columns='segmento', values='total').reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArGdP-XuaQf6"
      },
      "outputs": [],
      "source": [
        "def extract_ranking_new_autos(text):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados do ranking dos 50 Autos novos mais comercializados no mês\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    pattern = r'(\\d+º)\\s+([A-Za-z0-9/().\\- ]*?[A-Za-z][A-Za-z0-9/().\\- ]*?)\\s+(\\d{1,3}(?:\\.\\d{3})*|\\d+)(?=\\s|$)'\n",
        "    data = re.findall(pattern, \"\\n\".join(lines))\n",
        "    return data[:50]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos_new:\n",
        "    if nome_arquivo.endswith('.pdf'):\n",
        "        caminho_pdf = os.path.join(path_new, nome_arquivo)\n",
        "\n",
        "        pdf_document = fitz.open(caminho_pdf)\n",
        "\n",
        "        todo_texto = \"\"\n",
        "        for num_pagina in range(pdf_document.page_count):\n",
        "            pagina = pdf_document[num_pagina]\n",
        "            todo_texto += pagina.get_text(\"text\")\n",
        "\n",
        "        pdf_document.close()\n",
        "\n",
        "        data = extract_ranking_new_autos(todo_texto)\n",
        "\n",
        "        if data:\n",
        "            match = re.search(r'(\\d{4}_\\d{2})', nome_arquivo)\n",
        "            if match:\n",
        "                ano_mes = match.group(1)\n",
        "            else:\n",
        "                print(f\"Aviso: padrão 'YYYY_MM' não encontrado em {nome_arquivo}\")\n",
        "                continue\n",
        "\n",
        "            for i, dados_entrada in enumerate(data, start=1):\n",
        "                lista_entrada = list(dados_entrada)\n",
        "                lista_entrada[0] = f\"{i}º\"\n",
        "                lista_entrada.append(ano_mes)\n",
        "                all_data.append(lista_entrada)\n",
        "\n",
        "new_autos = pd.DataFrame(all_data, columns=['ranking', 'model', 'total', 'ano_mes'])\n",
        "new_autos.drop_duplicates(inplace=True)\n",
        "new_autos['total'] = new_autos['total'].str.replace('.', '').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZuuHKBmHLjR"
      },
      "outputs": [],
      "source": [
        "def extract_ranking_new_light(text):\n",
        "    \"\"\"\"\n",
        "    Extrai via regex os dados do ranking dos 50 Comerciais Leves novos mais comercializados no mês\n",
        "    \"\"\"\n",
        "    blocos = re.split(r'(?=\\d{1,2}º)', text)\n",
        "\n",
        "    resultados = []\n",
        "    for bloco in blocos:\n",
        "        match = re.search(r'(\\d+º)\\s+([\\w/.\\- ()]+?)\\s+(\\d{1,3}(?:\\.\\d{3})*|\\d+)(?=\\s+\\d+º|\\s+Ed\\.|$)', bloco.strip())\n",
        "        if match:\n",
        "            ranking = match.group(1)\n",
        "            modelo = match.group(2).strip()\n",
        "            total = match.group(3).replace('.', '')\n",
        "            resultados.append((ranking, modelo, total))\n",
        "    return resultados[49:99]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for nome_arquivo in lista_arquivos_new:\n",
        "    if nome_arquivo.endswith('.pdf'):\n",
        "        caminho_pdf = os.path.join(path_new, nome_arquivo)\n",
        "\n",
        "        pdf_document = fitz.open(caminho_pdf)\n",
        "\n",
        "        todo_texto = \"\"\n",
        "        for num_pagina in range(pdf_document.page_count):\n",
        "            pagina = pdf_document[num_pagina]\n",
        "            todo_texto += pagina.get_text(\"text\")\n",
        "\n",
        "        pdf_document.close()\n",
        "\n",
        "        data = extract_ranking_new_light(todo_texto)\n",
        "\n",
        "        if data:\n",
        "            match = re.search(r'(\\d{4}_\\d{2})', nome_arquivo)\n",
        "            if match:\n",
        "                ano_mes = match.group(1)\n",
        "            else:\n",
        "                print(f\"Aviso: padrão 'YYYY_MM' não encontrado em {nome_arquivo}\")\n",
        "                continue \n",
        "\n",
        "            for i, dados_entrada in enumerate(data, start=1):\n",
        "                lista_entrada = list(dados_entrada)\n",
        "                lista_entrada[0] = f\"{i}º\"\n",
        "                lista_entrada.append(ano_mes)\n",
        "                all_data.append(lista_entrada)\n",
        "\n",
        "new_leves = pd.DataFrame(all_data, columns=[\"ranking\", \"model\", \"total\", \"ano_mes\"])\n",
        "new_leves.drop_duplicates(inplace=True)\n",
        "new_leves['total'] = new_leves['total'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvShBbiTM6e_"
      },
      "outputs": [],
      "source": [
        "# Extrai o número do ranking para facilitar ordenação\n",
        "new_leves[\"ranking_num\"] = new_leves[\"ranking\"].str.extract(r\"(\\d+)\").astype(int)\n",
        "\n",
        "# Ordena pra garantir que o 1º ranking vem primeiro dentro de cada grupo\n",
        "new_leves = new_leves.sort_values(by=[\"ano_mes\", \"ranking_num\"]).reset_index(drop=True)\n",
        "\n",
        "# Pega o total do 1º colocado por mês\n",
        "primeiro_colocado = new_leves[new_leves[\"ranking_num\"] == 1][[\"ano_mes\", \"total\"]]\n",
        "primeiro_colocado = primeiro_colocado.rename(columns={\"total\": \"total_top1\"})\n",
        "\n",
        "# Faz merge pra comparar todos os totais com o do 1º colocado\n",
        "leves_merge = new_leves.merge(primeiro_colocado, on=\"ano_mes\", how=\"left\")\n",
        "\n",
        "# Mantém só linhas cujo total seja menor ou igual ao do primeiro colocado\n",
        "new_leves_filtrado = leves_merge[leves_merge[\"total\"] <= leves_merge[\"total_top1\"]].copy()\n",
        "\n",
        "# Remove colunas auxiliares se quiser\n",
        "new_leves_filtrado = new_leves_filtrado.drop(columns=[\"ranking_num\", \"total_top1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0vuErLeaU8T"
      },
      "source": [
        "### Salvar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6cNCao3HqQE"
      },
      "outputs": [],
      "source": [
        "path_credentials = ''\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(path_credentials, scope)\n",
        "client = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6Ga97pzQoNK"
      },
      "outputs": [],
      "source": [
        "# Seminovos e Usados\n",
        "segmento_total_used = client.create(\"20250601_Seminovos_Usados_Fenabrave_v2\")\n",
        "sheet1 = segmento_total_used.sheet1\n",
        "set_with_dataframe(sheet1, pivot_df_total_used)\n",
        "segmento_total_used.add_worksheet(title=\"Autos\", rows=str(len(used_autos)), cols=\"20\")\n",
        "sheet2 = segmento_total_used.worksheet(\"Autos\")\n",
        "set_with_dataframe(sheet2, used_autos)\n",
        "segmento_total_used.add_worksheet(title=\"Comerciais Leves\", rows=str(len(used_leves)), cols=\"20\")\n",
        "sheet3 = segmento_total_used.worksheet(\"Comerciais Leves\")\n",
        "set_with_dataframe(sheet3, used_leves)\n",
        "\n",
        "\n",
        "# Emplacamentos\n",
        "segmento_total_new = client.create(\"20250601_Emplacamentos_Fenabrave_v1\")\n",
        "sheet1 = segmento_total_new.sheet1\n",
        "set_with_dataframe(sheet1, pivot_df_total_new)\n",
        "segmento_total_new.add_worksheet(title=\"Autos\", rows=str(len(new_autos)), cols=\"20\")\n",
        "sheet2 = segmento_total_new.worksheet(\"Autos\")\n",
        "set_with_dataframe(sheet2, new_autos)\n",
        "segmento_total_new.add_worksheet(title=\"Comerciais Leves\", rows=str(len(new_leves_filtrado)), cols=\"20\")\n",
        "sheet3 = segmento_total_new.worksheet(\"Comerciais Leves\")\n",
        "set_with_dataframe(sheet3, new_leves_filtrado)\n",
        "\n",
        "# Compartilhamento com os emails\n",
        "emails = ['lucas.nasc.m@gmail.com', 'lucas.moreira@olxbr.com']\n",
        "for email in emails:\n",
        "    segmento_total_used.share(email, perm_type='user', role='writer')\n",
        "    segmento_total_new.share(email, perm_type='user', role='writer')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ecj6H9W1T-4q"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.9.15",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
